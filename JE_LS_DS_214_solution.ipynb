{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JE - LS_DS_214_solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xppJPDg7kKZ"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9jdsLq17kKf"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "#else:\n",
        "    #DATA_PATH = '../data/'"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUgbykv37kKg"
      },
      "source": [
        "# Module Project: Logistic Regression\n",
        "\n",
        "Do you like burritos? ðŸŒ¯ You're in luck then, because in this project you'll create a model to predict whether a burrito is `'Great'`.\n",
        "\n",
        "The dataset for this assignment comes from [Scott Cole](https://srcole.github.io/100burritos/), a San Diego-based data scientist and burrito enthusiast. \n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are the following:\n",
        "\n",
        "- **Task 1:** Import `csv` file using `wrangle` function.\n",
        "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function .\n",
        "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build `model_logr` using a pipeline that includes three transfomers and `LogisticRegression` predictor. Train model on `X_train` and `X_test`.\n",
        "- **Task 7:** Calculate the training and test accuracy score for your model.\n",
        "- **Task 8:** Create a horizontal bar chart showing the 10 most influencial features for your  model. \n",
        "- **Task 9:** Demonstrate and explain the differences between `model_lr.predict()` and `model_lr.predict_proba()`.\n",
        "\n",
        "**Note** \n",
        "\n",
        "You should limit yourself to the following libraries:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBBv476h7kKh"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwLZv5-l7kKi"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from category_encoders import OneHotEncoder\n",
        "\n",
        "def wrangle(filepath):\n",
        "    # Import w/ DateTimeIndex\n",
        "    df = pd.read_csv(filepath, parse_dates=['Date'],\n",
        "                     index_col='Date')\n",
        "    # Drop unrated burritos\n",
        "    df.dropna(subset=['overall'], inplace=True)\n",
        "    # Derive binary classification target:\n",
        "    # We define a 'Great' burrito as having an\n",
        "    # overall rating of 4 or higher, on a 5 point scale\n",
        "    df['Great'] = (df['overall'] >= 4).astype(int)\n",
        "    # Drop high cardinality categoricals\n",
        "    df = df.drop(columns=['Notes', 'Location', 'Address', 'URL', 'Neighborhood'])\n",
        "    cutoff = 10\n",
        "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "              if df[col].nunique() > cutoff]\n",
        "    #Burrito categories\n",
        "    df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "    california = df['Burrito'].str.contains('california')\n",
        "    asada = df['Burrito'].str.contains('asada')\n",
        "    surf = df['Burrito'].str.contains('surf')\n",
        "    carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "    df.loc[california, 'Burrito'] = 'California'\n",
        "    df.loc[asada, 'Burrito'] = 'Asada'\n",
        "    df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "    df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "    df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'\n",
        "    # Drop columns to prevent \"leakage\"\n",
        "    df = df.drop(columns=['Rec', 'overall'])\n",
        "    df = df.drop(columns=drop_cols)\n",
        "    # Categorical Variables, change uppercase to lowercase\n",
        "    for col in df.select_dtypes('object').columns:\n",
        "      df[col] = df[col].str.lower()\n",
        "    # Nan to 0\n",
        "    df = df.fillna(0)\n",
        "    #x to 1\n",
        "    df =  df.replace('x', 1) \n",
        "    \n",
        "    return df\n",
        "filepath = DATA_PATH + 'burritos/burritos.csv'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzHRSYax7kKi"
      },
      "source": [
        "**Task 1:** Use the above `wrangle` function to import the `burritos.csv` file into a DataFrame named `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP_DDVf77kKj"
      },
      "source": [
        "filepath = (DATA_PATH + 'burritos/burritos.csv')\n",
        "df = wrangle(filepath)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAFbU4Vo7kKj"
      },
      "source": [
        "During your exploratory data analysis, note that there are several columns whose data type is `object` but that seem to be a binary encoding. For example, `df['Beef'].head()` returns:\n",
        "\n",
        "```\n",
        "0      x\n",
        "1      x\n",
        "2    NaN\n",
        "3      x\n",
        "4      x\n",
        "Name: Beef, dtype: object\n",
        "```\n",
        "\n",
        "**Task 2:** Change the `wrangle` function so that these columns are properly encoded as `0` and `1`s. Be sure your code handles upper- and lowercase `X`s, and `NaN`s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8hib7gr7kKk"
      },
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above."
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "XSmptWrlB1e4",
        "outputId": "b19da37a-1d67-45a3-d137-ec44f3d478a8"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Yelp  Google Chips  Cost  ...  Avocado  Corn  Zucchini  Great\n",
              "Date                                  ...                                \n",
              "2016-01-18   3.5     4.2     0  6.49  ...        0     0         0      0\n",
              "2016-01-24   3.5     3.3     0  5.45  ...        0     0         0      0\n",
              "2016-01-24   0.0     0.0     0  4.85  ...        0     0         0      0\n",
              "2016-01-24   0.0     0.0     0  5.25  ...        0     0         0      0\n",
              "2016-01-27   4.0     3.8     1  6.59  ...        0     0         0      1\n",
              "\n",
              "[5 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "CKfP0ronFcSK",
        "outputId": "6a2c4633-2a60-454d-f917-2d3e3fb29854"
      },
      "source": [
        "df"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.5</td>\n",
              "      <td>0.57</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.02</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.90</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.77</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.90</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>24.5</td>\n",
              "      <td>1.07</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-08-27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>21.3</td>\n",
              "      <td>0.61</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>421 rows Ã— 57 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Yelp  Google Chips  Cost  ...  Avocado  Corn  Zucchini  Great\n",
              "Date                                  ...                                \n",
              "2016-01-18   3.5     4.2     0  6.49  ...        0     0         0      0\n",
              "2016-01-24   3.5     3.3     0  5.45  ...        0     0         0      0\n",
              "2016-01-24   0.0     0.0     0  4.85  ...        0     0         0      0\n",
              "2016-01-24   0.0     0.0     0  5.25  ...        0     0         0      0\n",
              "2016-01-27   4.0     3.8     1  6.59  ...        0     0         0      1\n",
              "...          ...     ...   ...   ...  ...      ...   ...       ...    ...\n",
              "2019-08-27   0.0     0.0     0  6.00  ...        0     0         0      0\n",
              "2019-08-27   0.0     0.0     0  6.00  ...        0     0         0      1\n",
              "2019-08-27   0.0     0.0     0  7.90  ...        0     0         0      0\n",
              "2019-08-27   0.0     0.0     0  7.90  ...        0     0         0      1\n",
              "2019-08-27   0.0     0.0     0  5.50  ...        0     0         0      1\n",
              "\n",
              "[421 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg7bS2ZSB3bG",
        "outputId": "f5c2785f-01a8-4e27-aa5e-395ea5ed4a62"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(421, 57)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNQmOD2nB5Vu",
        "outputId": "035f655a-520f-4ae0-a38b-437328477044"
      },
      "source": [
        "df.info"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of             Yelp  Google Chips  Cost  ...  Avocado  Corn  Zucchini  Great\n",
              "Date                                  ...                                \n",
              "2016-01-18   3.5     4.2     0  6.49  ...        0     0         0      0\n",
              "2016-01-24   3.5     3.3     0  5.45  ...        0     0         0      0\n",
              "2016-01-24   0.0     0.0     0  4.85  ...        0     0         0      0\n",
              "2016-01-24   0.0     0.0     0  5.25  ...        0     0         0      0\n",
              "2016-01-27   4.0     3.8     1  6.59  ...        0     0         0      1\n",
              "...          ...     ...   ...   ...  ...      ...   ...       ...    ...\n",
              "2019-08-27   0.0     0.0     0  6.00  ...        0     0         0      0\n",
              "2019-08-27   0.0     0.0     0  6.00  ...        0     0         0      1\n",
              "2019-08-27   0.0     0.0     0  7.90  ...        0     0         0      0\n",
              "2019-08-27   0.0     0.0     0  7.90  ...        0     0         0      1\n",
              "2019-08-27   0.0     0.0     0  5.50  ...        0     0         0      1\n",
              "\n",
              "[421 rows x 57 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVgkT4-W7kKk"
      },
      "source": [
        "If you explore the `'Burrito'` column of `df`, you'll notice that it's a high-cardinality categorical feature. You'll also notice that there's a lot of overlap between the categories. \n",
        "\n",
        "**Stretch Goal:** Change the `wrangle` function above so that it engineers four new features: `'california'`, `'asada'`, `'surf'`, and `'carnitas'`. Each row should have a `1` or `0` based on the text information in the `'Burrito'` column. For example, here's how the first 5 rows of the dataset would look.\n",
        "\n",
        "| **Burrito** | **california** | **asada** | **surf** | **carnitas** |\n",
        "| :---------- | :------------: | :-------: | :------: | :----------: |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "|  Carnitas   |       0        |     0     |    0     |      1       |\n",
        "| Carne asada |       0        |     1     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "\n",
        "**Note:** Be sure to also drop the `'Burrito'` once you've engineered your new features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5heZP7oV7kKl"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your dataset into the feature matrix `X` and the target vector `y`. You want to predict `'Great'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyAyMyBy7kKm"
      },
      "source": [
        "target = 'Great'\n",
        "y = df[target]\n",
        "X = df.drop(columns=target)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-m4g4e47kKn"
      },
      "source": [
        "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
        "\n",
        "- Your training set should include data from 2016 through 2017. \n",
        "- Your test set should include data from 2018 and later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTlPx1ztAkXg",
        "outputId": "38cff033-e7e3-4f0c-a5c2-b087b8fd3d9d"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "421"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2JzCpDM7kKn"
      },
      "source": [
        "#might need to specify the first 2018 date featured in the dataset if this doesn't run\n",
        "#cutoff = '2018-01-01'\n",
        "#mask = X.index < cutoff\n",
        "\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=  , )\n",
        "\n",
        "#First splitting to train and test\n",
        "#X_train, X_test, y_train, y_test \n",
        "    #= train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "#Second splitting to train again into validation and train\n",
        " #X_train, X_val, y_train, y_val \n",
        "    #= train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "#This is randomized. 0.2 is for 20%. Setting aside some of my data for the validation\n",
        "#X_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=72)\n",
        "\n",
        "cutoff_1 = '2017-01-01'\n",
        "mask_1 = df.index < cutoff_1\n",
        "cutoff_2 = '2018-01-01'\n",
        "mask_2 = (df.index < cutoff_2) & (df.index >= cutoff_1)\n",
        "mask_3 = df.index > cutoff_2\n",
        "\n",
        "X_train, y_train = X.loc[mask_1], y.loc[mask_1]\n",
        "X_val, y_val = X.loc[mask_2], y.loc[mask_2]\n",
        "\n",
        "X_test, y_test = X.loc[mask_3], y.loc[mask_3]\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q70kEa1R7kKn"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-67mxHl7kKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29350f8a-2ff6-4438-cbf0-fb5fc6593880"
      },
      "source": [
        "baseline_acc = y_train.value_counts(normalize=True).max()\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline Accuracy Score: 0.5906040268456376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYDUF9j3XgGd"
      },
      "source": [
        "y_pred = [y_train.mean()] * len(y_train)\n",
        "\n",
        "baseline_mae = mean_absolute_error(y_train, y_pred)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIMztKeX7kKo"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_logr`, and fit it to your training data. Your pipeline should include:\n",
        "\n",
        "- a `OneHotEncoder` transformer for categorical features, \n",
        "- a `SimpleImputer` transformer to deal with missing values, \n",
        "- a [`StandarScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) transfomer (which often improves performance in a logistic regression model), and \n",
        "- a `LogisticRegression` predictor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08R5fZ3L7kKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec81672b-7d60-4eaa-d6b7-ca8b0954fc16"
      },
      "source": [
        "model_lr = make_pipeline(\n",
        "    OneHotEncoder(use_cat_names=True),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(C=0.008)\n",
        ")\n",
        "     \n",
        "model_lr.fit(X_train, y_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('onehotencoder',\n",
              "                 OneHotEncoder(cols=['Chips'], drop_invariant=False,\n",
              "                               handle_missing='value', handle_unknown='value',\n",
              "                               return_df=True, use_cat_names=True, verbose=0)),\n",
              "                ('simpleimputer',\n",
              "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
              "                               missing_values=nan, strategy='mean',\n",
              "                               verbose=0)),\n",
              "                ('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('logisticregression',\n",
              "                 LogisticRegression(C=0.008, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFtSEgHb7kKo"
      },
      "source": [
        "# IV. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and test accuracy score for `model_lr`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6ddqeq47kKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f261856-991f-418d-f035-524cc4f84147"
      },
      "source": [
        "training_acc = model_lr.score(X_train, y_train)\n",
        "test_acc = model_lr.score(X_val, y_val)\n",
        "\n",
        "print('Training MAE:', training_acc)\n",
        "print('Test MAE:', test_acc)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MAE: 0.87248322147651\n",
            "Test MAE: 0.8705882352941177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovQR5pkG7kKp"
      },
      "source": [
        "# V. Communicate Results\n",
        "\n",
        "**Task 8:** Create a horizontal barchart that plots the 10 most important coefficients for `model_lr`, sorted by absolute value.\n",
        "\n",
        "**Note:** Since you created your model using a `Pipeline`, you'll need to use the [`named_steps`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) attribute to access the coefficients in your `LogisticRegression` predictor. Be sure to look at the shape of the coefficients array before you combine it with the feature names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZIn5G3BOFqx",
        "outputId": "3e6fffc3-ad4c-47b7-852f-0f3c4c281737"
      },
      "source": [
        "type(model_lr.named_steps['logisticregression'])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.linear_model._logistic.LogisticRegression"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y6rsvT_PUH-",
        "outputId": "494ab7de-448c-49da-b123-cb085938e1a4"
      },
      "source": [
        "#Check attributes for ohe\n",
        "dir(model_lr.named_steps['onehotencoder'])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_dim',\n",
              " '_get_param_names',\n",
              " '_get_tags',\n",
              " '_more_tags',\n",
              " 'category_mapping',\n",
              " 'cols',\n",
              " 'drop_cols',\n",
              " 'drop_invariant',\n",
              " 'feature_names',\n",
              " 'fit',\n",
              " 'fit_transform',\n",
              " 'generate_mapping',\n",
              " 'get_dummies',\n",
              " 'get_feature_names',\n",
              " 'get_params',\n",
              " 'handle_missing',\n",
              " 'handle_unknown',\n",
              " 'inverse_transform',\n",
              " 'mapping',\n",
              " 'ordinal_encoder',\n",
              " 'return_df',\n",
              " 'reverse_dummies',\n",
              " 'set_params',\n",
              " 'transform',\n",
              " 'use_cat_names',\n",
              " 'verbose']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5PGEmigFAqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ebee5c-ba54-4812-8243-d7e5bbff364c"
      },
      "source": [
        "len(model_lr.named_steps['onehotencoder'].get_feature_names())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N7cdzpb7kKq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "266d1a52-87cc-4dd5-e48f-66b7473e0020"
      },
      "source": [
        "# Create your horizontal barchart here.\n",
        "coefficients = model_lr.named_steps['logisticregression'].coef_[0]\n",
        "features = model_lr.named_steps['onehotencoder'].get_feature_names()\n",
        "feat_imp = pd.Series(coefficients, index=features).sort_values(key=abs)\n",
        "feat_imp.tail(10).plot(kind='barh')\n",
        "plt.xlabel('Coefficient')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Coefficients for Logistic Regression');"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVLNaSAi7kKr"
      },
      "source": [
        "There is more than one way to generate predictions with `model_lr`. For instance, you can use [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) or [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression.predict_proba).\n",
        "\n",
        "**Task 9:** Generate predictions for `X_test` using both `predict` and `predict_proba`. Then below, write a summary of the differences in the output for these two methods. You should answer the following questions:\n",
        "\n",
        "- What data type do `predict` and `predict_proba` output?\n",
        "- What are the shapes of their different output?\n",
        "- What numerical values are in the output?\n",
        "- What do those numerical values represent?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoPdPSR_TtgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda09b96-bdd4-4b85-9ae4-fcdbe95ab4b8"
      },
      "source": [
        "# Write code here to explore the differences between `predict` and `predict_proba`.\n",
        "y_pred = model_lr.predict(X_test)\n",
        "\n",
        "#to look at my values, number used inbetween [: ]\n",
        "y_pred[:10]\n",
        "\n",
        "#First ten values returned are my predictions"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 0, 0, 1, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoQpkKMm7kKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638fabbf-e676-45b3-ce00-98b10860b43b"
      },
      "source": [
        "# Confirming the probability of accuracy  of prediction\n",
        "y_pred_proba = model_lr.predict_proba(X_test)\n",
        "\n",
        "y_pred_proba[:10]   \n",
        "#returns an array with two columns. First column is for 0s, second column is for 1s\n",
        "#Which column are we interested in concerning the returns of 0s and 1s for Great Burritos?"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.17084772, 0.82915228],\n",
              "       [0.26576117, 0.73423883],\n",
              "       [0.55573369, 0.44426631],\n",
              "       [0.08411062, 0.91588938],\n",
              "       [0.73125683, 0.26874317],\n",
              "       [0.6416471 , 0.3583529 ],\n",
              "       [0.48965993, 0.51034007],\n",
              "       [0.27183866, 0.72816134],\n",
              "       [0.6411756 , 0.3588244 ],\n",
              "       [0.41714872, 0.58285128]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n7sAr1mVCjR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7e68b2-29ce-453c-de18-3841ff83815b"
      },
      "source": [
        "# To only select the 1 column. The list of values are degrees of certainty for my model believing it's a 1.\n",
        "y_pred_proba[:10, -1] "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.82915228, 0.73423883, 0.44426631, 0.91588938, 0.26874317,\n",
              "       0.3583529 , 0.51034007, 0.72816134, 0.3588244 , 0.58285128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPWzGiO9XFEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6c88f5-802b-43ff-c9da-9e1ce2eb37d8"
      },
      "source": [
        "print(y_pred.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9QVzlvMXIKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b847b315-27b6-4893-9bad-7080584dd4ba"
      },
      "source": [
        "print(y_pred_proba.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4tCodEn7kKr"
      },
      "source": [
        "**Give your written answer here:**\n",
        "\n",
        "```\n",
        "The predict function is used not only to gain classes, but probability. While the predict_proba function is used to return the probability of accuracy of prediction.\n",
        "\n",
        "\n",
        "\n",
        "What data type do predict and predict_proba output?\n",
        "\n",
        "predict returns integers, while predict_proba returns floats.\n",
        "\n",
        "\n",
        "\n",
        "What are the shapes of their different output?\n",
        "\n",
        "predict has a shape of (38,), while predict_proba has a shape of (38, 2).\n",
        "\n",
        "\n",
        "\n",
        "What numerical values are in the output?\n",
        "\n",
        "The numerical values returned in the output for both predict and predict_proba are arrays. predict_proba differs by featuring arrays in the form of two columns.\n",
        "\n",
        "\n",
        "\n",
        "What do those numerical values represent?\n",
        "\n",
        "The numerical values represent degrees of certainty for our model believing our target to be one of two values, 0 or 1.\n",
        "\n",
        "```"
      ]
    }
  ]
}